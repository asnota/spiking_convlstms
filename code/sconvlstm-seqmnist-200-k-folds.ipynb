{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# Install SNN dependency\n!pip install snntorch\n\nimport snntorch as snn\nfrom snntorch import surrogate\n\nimport numpy as np\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader, SubsetRandomSampler\nimport torchvision\nimport torchvision.transforms as T\nfrom sklearn.model_selection import KFold\nimport os\nimport copy\n\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python --version","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%pip install codecarbon comet_ml","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from comet_ml import Experiment\nfrom codecarbon import EmissionsTracker\nfrom datetime import datetime\n\n# Initialise and start CodeCarbon tracker\ntracker = EmissionsTracker()\ntracker.start()\n\nstart_time = datetime.now()\nprint(f'Start time is {start_time}')\n\n# Initialise the Comet experiment\nexperiment = Experiment(\n    api_key=\"XXXXXXXXXXXXXXXXXXXXXXXXX\",\n    project_name=\"\",\n    workspace=\"\",\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of numbers in a sequence\n\nsequences = [\n    [1, 2, 3, 6, 8],\n    [1, 4, 3, 6, 8],\n    [1, 5, 3, 6, 8],\n\n    [1, 2, 3, 6, 9],\n    [1, 4, 3, 6, 9],\n    [1, 5, 3, 6, 9],\n\n    [1, 2, 3, 7, 8],\n    [1, 4, 3, 7, 8],\n    [1, 5, 3, 7, 8],\n\n    [1, 2, 3, 7, 9],\n    [1, 4, 3, 7, 9],\n    [1, 5, 3, 7, 9],\n    #________________ 12\n\n    [1, 2, 6, 7, 8],\n    [1, 4, 6, 7, 8],\n    [1, 5, 6, 7, 8],\n\n    [1, 2, 6, 7, 9],\n    [1, 4, 6, 7, 9],\n    [1, 5, 6, 7, 9],\n\n    [1, 2, 6, 3, 8],\n    [1, 4, 6, 3, 8],\n    [1, 5, 6, 3, 8],\n\n    [1, 2, 6, 3, 9],\n    [1, 4, 6, 3, 9],\n    [1, 5, 6, 3, 9],\n    #________________ 24\n    [1, 2, 7, 3, 8],\n    [1, 4, 7, 3, 8],\n    [1, 5, 7, 3, 8],\n\n    [1, 2, 7, 3, 9],\n    [1, 4, 7, 3, 9],\n    [1, 5, 7, 3, 9],\n\n    [1, 2, 7, 9, 8],\n    [1, 4, 7, 9, 8],\n    [1, 5, 7, 9, 8],\n\n    [1, 2, 7, 8, 9],\n    [1, 4, 7, 8, 9],\n    [1, 5, 7, 8, 9],\n    #________________ 36\n    [2, 3, 4, 7, 8],\n    [2, 5, 4, 7, 8],\n    [2, 6, 4, 7, 8],\n\n    [2, 3, 4, 7, 9],\n    [2, 5, 4, 7, 9],\n    [2, 6, 4, 7, 9],\n\n    [2, 3, 4, 1, 8],\n    [2, 5, 4, 1, 8],\n    [2, 6, 4, 1, 8],\n\n    [2, 3, 4, 1, 9],\n    [2, 5, 4, 1, 9],\n    [2, 6, 4, 1, 9],\n    #________________ 48\n    [2, 3, 7, 8, 9],\n    [2, 5, 7, 8, 9],\n    [2, 6, 7, 8, 9],\n\n    [2, 3, 7, 9, 8],\n    [2, 5, 7, 9, 8],\n    [2, 6, 7, 9, 8],\n\n    [2, 3, 7, 8, 1],\n    [2, 5, 7, 8, 1],\n    [2, 6, 7, 8, 1],\n\n    [2, 3, 7, 9, 1],\n    [2, 5, 7, 9, 1],\n    [2, 6, 7, 9, 1],\n    #________________ 60\n    [2, 3, 8, 9, 1],\n    [2, 5, 8, 9, 1],\n    [2, 6, 8, 9, 1],\n\n    [2, 3, 8, 9, 7],\n    [2, 5, 8, 9, 7],\n    [2, 6, 8, 9, 7],\n\n    [2, 3, 8, 7, 1],\n    [2, 5, 8, 7, 1],\n    [2, 6, 8, 7, 1],\n\n    [2, 3, 8, 1, 7],\n    [2, 5, 8, 1, 7],\n    [2, 6, 8, 1, 7],\n    #________________ 72\n    [3, 4, 5, 8, 2],\n    [3, 6, 5, 8, 2],\n    [3, 7, 5, 8, 2],\n\n    [3, 4, 5, 2, 8],\n    [3, 6, 5, 2, 8],\n    [3, 7, 5, 2, 8],\n\n    [3, 4, 5, 8, 1],\n    [3, 6, 5, 8, 1],\n    [3, 7, 5, 8, 1],\n\n    [3, 4, 5, 1, 8],\n    [3, 6, 5, 1, 8],\n    [3, 7, 5, 1, 8],\n    #_______________ 84\n    [3, 4, 8, 9, 2],\n    [3, 6, 8, 9, 2],\n    [3, 7, 8, 9, 2],\n\n    [3, 4, 8, 2, 9],\n    [3, 6, 8, 2, 9],\n    [3, 7, 8, 2, 9],\n\n    [3, 4, 8, 9, 1],\n    [3, 6, 8, 9, 1],\n    [3, 7, 8, 9, 1],\n\n    [3, 4, 8, 1, 9],\n    [3, 6, 8, 1, 9],\n    [3, 7, 8, 1, 9],\n    #_______________ 96\n    [3, 4, 9, 8, 2],\n    [3, 6, 9, 8, 2],\n    [3, 7, 9, 8, 2],\n\n    [3, 4, 9, 2, 8],\n    [3, 6, 9, 2, 8],\n    [3, 7, 9, 2, 8],\n\n    [3, 4, 9, 8, 1],\n    [3, 6, 9, 8, 1],\n    [3, 7, 9, 8, 1],\n\n    [3, 4, 9, 1, 8],\n    [3, 6, 9, 1, 8],\n    [3, 7, 9, 1, 8],\n    #_______________ 108\n    [4, 5, 6, 9, 2],\n    [4, 7, 6, 9, 2],\n    [4, 8, 6, 9, 2],\n\n    [4, 5, 6, 2, 9],\n    [4, 7, 6, 2, 9],\n    [4, 8, 6, 2, 9],\n\n    [4, 5, 6, 9, 3],\n    [4, 7, 6, 9, 3],\n    [4, 8, 6, 9, 3],\n\n    [4, 5, 6, 3, 9],\n    [4, 7, 6, 3, 9],\n    [4, 8, 6, 3, 9],\n    #_______________ 120\n    [4, 5, 9, 3, 2],\n    [4, 7, 9, 3, 2],\n    [4, 8, 9, 3, 2],\n\n    [4, 5, 9, 2, 3],\n    [4, 7, 9, 2, 3],\n    [4, 8, 9, 2, 3],\n\n    [4, 5, 9, 1, 3],\n    [4, 7, 9, 1, 3],\n    [4, 8, 9, 1, 3],\n\n    [4, 5, 9, 3, 1],\n    [4, 7, 9, 3, 1],\n    [4, 8, 9, 3, 1],\n    #_______________ 132\n    [4, 5, 1, 3, 2],\n    [4, 7, 1, 3, 2],\n    [4, 8, 1, 3, 2],\n\n    [4, 5, 1, 2, 3],\n    [4, 7, 1, 2, 3],\n    [4, 8, 1, 2, 3],\n\n    [4, 5, 1, 9, 3],\n    [4, 7, 1, 9, 3],\n    [4, 8, 1, 9, 3],\n\n    [4, 5, 1, 3, 9],\n    [4, 7, 1, 3, 9],\n    [4, 8, 1, 3, 9],\n    #_______________ 144\n    [5, 6, 7, 1, 2],\n    [5, 8, 7, 1, 2],\n    [5, 9, 7, 1, 2],\n\n    [5, 6, 7, 2, 1],\n    [5, 8, 7, 2, 1],\n    [5, 9, 7, 2, 1],\n\n    [5, 6, 7, 3, 2],\n    [5, 8, 7, 3, 2],\n    [5, 9, 7, 3, 2],\n\n    [5, 6, 7, 2, 3],\n    [5, 8, 7, 2, 3],\n    [5, 9, 7, 2, 3],\n    #_______________ 156\n    [5, 6, 1, 2, 3],\n    [5, 8, 1, 2, 3],\n    [5, 9, 1, 2, 3],\n\n    [5, 6, 1, 3, 2],\n    [5, 8, 1, 3, 2],\n    [5, 9, 1, 3, 2],\n\n    [5, 6, 1, 3, 4],\n    [5, 8, 1, 3, 4],\n    [5, 9, 1, 3, 4],\n\n    [5, 6, 1, 4, 3],\n    [5, 8, 1, 4, 3],\n    [5, 9, 1, 4, 3],\n    #_______________ 168\n    [5, 6, 3, 4, 1],\n    [5, 8, 3, 4, 1],\n    [5, 9, 3, 4, 1],\n\n    [5, 6, 3, 1, 4],\n    [5, 8, 3, 1, 4],\n    [5, 9, 3, 1, 4],\n\n    [5, 6, 3, 4, 2],\n    [5, 8, 3, 4, 2],\n    [5, 9, 3, 4, 2],\n\n    [5, 6, 3, 2, 4],\n    [5, 8, 3, 2, 4],\n    [5, 9, 3, 2, 4],\n    #_______________ 180\n    [6, 7, 8, 2, 3],\n    [6, 9, 8, 2, 3],\n    [6, 1, 8, 2, 3],\n\n    [6, 7, 8, 3, 2],\n    [6, 9, 8, 3, 2],\n    [6, 1, 8, 3, 2],\n\n    [6, 7, 8, 2, 5],\n    [6, 9, 8, 2, 5],\n    [6, 1, 8, 2, 5],\n\n    [6, 7, 8, 5, 2],\n    [6, 9, 8, 5, 2],\n    [6, 1, 8, 5, 2],\n    #_______________ 192\n    [6, 7, 2, 3, 4],\n    [6, 9, 2, 3, 4],\n    [6, 1, 2, 3, 4],\n\n    [6, 7, 2, 4, 3],\n    [6, 9, 2, 4, 3],\n    [6, 1, 2, 4, 3],\n\n    [6, 7, 2, 4, 5],\n    [6, 9, 2, 4, 5],\n    [6, 1, 2, 4, 5],\n\n    [6, 7, 2, 5, 4],\n    [6, 9, 2, 5, 4],\n    [6, 1, 2, 5, 4],\n    #_______________ 204\n    [6, 7, 3, 4, 5],\n    [6, 9, 3, 4, 5],\n    [6, 1, 3, 4, 5],\n\n    [6, 7, 3, 5, 4],\n    [6, 9, 3, 5, 4],\n    [6, 1, 3, 5, 4],\n\n    [6, 7, 3, 2, 5],\n    [6, 9, 3, 2, 5],\n    [6, 1, 3, 2, 5],\n\n    [6, 7, 3, 5, 2],\n    [6, 9, 3, 5, 2],\n    [6, 1, 3, 5, 2],\n    #_______________ 216\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = torchvision.datasets.MNIST(\"./\", train = False, download = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Patch images with labels\ndef find_match(number):\n    for entry in dataset:\n        if entry[1] == number:\n            match = entry\n            break\n    return match\n\nimage_sequences = []\nimage_label_sequences = []\nfor sequence in sequences:\n    image_sequence = []\n    image_label_sequence = []\n    for num in sequence:\n        entry = find_match(num)\n        image_sequence.append(entry[0])\n        image_label_sequence.append(entry)\n    image_sequences.append(image_sequence)\n    image_label_sequences.append(image_label_sequence)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert to matrices and resize\n\ntf = T.Compose([\n     T.Resize((28)),\n     T.ToTensor() # Returns a tensor with normalized values between 0 and 1\n])\nseqs = []\n\nfor seq in image_sequences:\n    img_tensors = []\n    for img in seq:\n        img_tensor = tf(img)\n        img_tensors.append(img_tensor)\n    img_tensors_stack = torch.stack(img_tensors)\n    seqs.append(img_tensors_stack)\n\nseqs_stack = torch.stack(seqs)\nseqs_reshaped = seqs_stack.reshape(216, 1, 5, 28, 28)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resized_seqs_reshape_for_image = seqs_stack.reshape(216, 5, 28, 28, 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Utils\ndef collate(batch):\n    batch = torch.stack(batch)    \n    #batch = batch / 255.0\n    batch = batch.to(device)    \n    return batch[:,:,0:4], batch[:,:,4]\n\ndef reset_weights(m):\n  '''\n    Try resetting model weights to avoid\n    weight leakage.\n  '''\n  for layer in m.children():\n        if hasattr(layer, 'reset_parameters'):\n            print(f'Reset trainable parameters of layer = {layer}')\n            layer.reset_parameters()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(seqs_reshaped, batch_size=1, collate_fn=collate, drop_last=True, shuffle=True)\ndata, target = next(iter(train_loader))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### SConvLSTM layer\nclass SConvLSTMLayer(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size):\n\n        super(SConvLSTMLayer, self).__init__()\n        self.out_channels = out_channels\n\n        # We will unroll this over time steps        \n        # Params\n        spike_grad_lstm = surrogate.straight_through_estimator()\n\n        # SConvLSTM cell\n        self.sclstm = snn.SConv2dLSTM(in_channels=in_channels, out_channels=out_channels, \n                        kernel_size=kernel_size, max_pool=2, spike_grad=spike_grad_lstm)\n\n    def forward(self, X):\n        # X is a frame sequence (batch_size, num_channels, seq_len, height, width)\n        # Get the dimensions\n        batch_size, _, seq_len, height, width = X.size()\n        \n        # Initialize hidden states and outputs at t=0\n        syn1, mem1 = self.sclstm.init_sconv2dlstm()\n\n        # Initialize output\n        output = torch.zeros(batch_size, self.out_channels, seq_len, \n        height, width, device=device)\n        \n        spk_output = torch.zeros(batch_size, self.out_channels, seq_len, \n        14, 14, device=device)\n        \n        # Initialize Hidden State\n        H = torch.zeros(batch_size, self.out_channels, \n        height, width, device=device)\n\n        # Initialize Cell Input\n        C = torch.zeros(batch_size,self.out_channels, \n        height, width, device=device)\n\n        # Unroll over time steps\n        for time_step in range(seq_len):\n            spk, H, C = self.sclstm(X[:,:,time_step], H, C)\n            output[:,:,time_step] = H\n            spk_output[:,:,time_step] = spk\n        return output, spk_output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### SConvLSTM model 1 layer\n\nclass SConvLSTMModel(nn.Module):\n    def __init__(self, num_channels, num_kernels, kernel_size, padding):\n        super(SConvLSTMModel, self).__init__()\n        \n        # First csconvlstm layer\n        self.sconvlstm_layer = SConvLSTMLayer(in_channels=num_channels, out_channels=num_kernels,\n                                        kernel_size=kernel_size)\n        # Batchnorm layer\n        self.batchnorm3d = nn.BatchNorm3d(num_features=num_kernels)\n\n        # Convolutional Layer to predict output frame\n        self.conv = nn.Conv2d(\n            in_channels=num_kernels, out_channels=num_channels,\n            kernel_size=kernel_size, padding=padding)\n\n    def forward(self, X):\n        \n        # Forward propagation through all the layers\n        sconvlstm_layer_membrane, sconvlstm_layer_spikes = self.sconvlstm_layer(X)\n        sconvlstm_batchnorm = self.batchnorm3d(sconvlstm_layer_membrane)\n        \n        # Return only the last output frame\n        output = self.conv(sconvlstm_batchnorm[:,:,-1])\n        spikes_output = sconvlstm_layer_spikes[:,:,-1]\n        \n        return nn.Sigmoid()(output), spikes_output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### K-fold Cross Validator\n# Params\ntorch.manual_seed(42)\nnum_epochs = 100\ncriterion = nn.BCELoss(reduction='sum')\n\n# Fold results storage objects\ntrain_start_results = {}\nval_start_results = {}\n\ntrain_end_results = {}\nval_end_results = {}\n\n# Per fold epoch results storage objects\ntrain_results_per_epoch = []\nval_results_per_epoch = []\n\ntrain_results = []\nval_results = []\n\nspiked_targets_train = []\nspiked_targets_val = []\n\n# Define the K-fold Cross Validator\nk_folds = 5\nkfold = KFold(n_splits=k_folds, shuffle=True)\n\n# Whole dataset\ndataset = seqs_reshaped\n\n# K-fold Cross Validation model evaluation\nfor fold, (train_ids, val_ids) in enumerate(kfold.split(dataset)):\n    print(f'FOLD {fold}')\n    \n    # Sample elements randomly from a given list of ids, no replacement.\n    train_subsampler = SubsetRandomSampler(train_ids)\n    val_subsampler = SubsetRandomSampler(val_ids)\n    \n    # Define data loaders for training and testing data in this fold\n    train_loader = DataLoader(dataset, batch_size=15, collate_fn=collate, sampler=train_subsampler)\n    val_loader = DataLoader(dataset, batch_size=15, collate_fn=collate, sampler=val_subsampler)\n    \n    # Initialization\n    model = SConvLSTMModel(num_channels=1, num_kernels=28, kernel_size=(3, 3), padding=(1, 1)).to(device)\n    model.apply(reset_weights)  \n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n    \n    train_results_per_epoch = []\n    val_results_per_epoch = []\n    for epoch in range(1, num_epochs+1):\n        train_loss = 0                                                 \n        model.train()        \n        for batch, (x, y) in enumerate(train_loader, 1):\n            output, spikes = model(x)\n            \n            optimizer.zero_grad()\n            \n            loss_train = criterion(output.flatten(), y.flatten())       \n            loss_train.backward()\n            \n            optimizer.step()\n                                      \n            train_loss += loss_train.item()\n            #spiked_targets_train.append(spikes)\n        total_train_loss = train_loss / len(train_loader.dataset)\n        train_results_per_epoch.append(total_train_loss)\n        \n        val_loss = 0                                                 \n        model.eval()                                                   \n        with torch.no_grad():                                          \n            for x, y in val_loader:                          \n                output, spikes = model(x)                                   \n                loss_val = criterion(output.flatten(), y.flatten())                \n                val_loss += loss_val.item()\n                #spiked_targets_val.append(spikes)\n        total_val_loss = val_loss / len(val_loader.dataset)\n        val_results_per_epoch.append(total_val_loss)\n        \n        # Store scores        \n        if epoch == 1:\n            val_start_results[fold] = total_val_loss\n            train_start_results[fold] = total_train_loss\n        else:\n            val_end_results[fold] = total_val_loss\n            train_end_results[fold] = total_train_loss\n            \n        print(\"Epoch:{} Training Loss:{:.2f} Validation Loss:{:.2f}\\n\".format(\n            epoch, total_train_loss, total_val_loss))\n    train_results.append(train_results_per_epoch)\n    val_results.append(val_results_per_epoch)\n    \n    # Saving the model\n    save_path = f'./convlstm-seqgmnist200-model-fold-{fold}.pth'\n    torch.save(model.state_dict(), save_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Stop CO2 tracker and print emissions\n\nemissions: float = tracker.stop()\nprint(f\"Emissions: {emissions} kg\")\n\n# Calculate the time spent\nstop_time = datetime.now() - start_time\ntime_spend = start_time - stop_time\n\n# Time logs\nexperiment.log_metric(\"start_time\", start_time) \nexperiment.log_metric(\"stop_time\", stop_time)\nexperiment.log_metric(\"time_spend\", time_spend)\n\n# Turn off Comet\nexperiment.end()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print start fold results\nprint(f'Start K-FOLD RESULTS FOR {k_folds} FOLDS')\nsum = 0.0\nfor key, value in train_start_results.items():\n    print(f'Fold {key}: {value}')\n    sum += value\nprint(f'Average train: {sum/len(train_start_results.items())}')\n\nsum = 0.0\nfor key, value in val_start_results.items():\n    print(f'Fold {key}: {value}')\n    sum += value\nprint(f'Average val: {sum/len(val_start_results.items())}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print final fold results\nprint(f'End K-FOLD RESULTS FOR {k_folds} FOLDS')\nsum = 0.0\nfor key, value in train_end_results.items():\n    print(f'Fold {key}: {value}')\n    sum += value\nprint(f'Average train: {sum/len(train_end_results.items())}')\n\nsum = 0.0\nfor key, value in val_end_results.items():\n    print(f'Fold {key}: {value}')\n    sum += value\nprint(f'Average val: {sum/len(val_end_results.items())}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n# Train and validation results\n\nx = list(range(0, 100))\n\nfig, ax = plt.subplots()\nt1, = ax.plot(x, train_results[0], c=\"blue\")\nt2, = ax.plot(x, train_results[1], c=\"brown\")\nt3, = ax.plot(x, train_results[2], c=\"green\")\nt4, = ax.plot(x, train_results[3], c=\"orange\")\nt5, = ax.plot(x, train_results[4], c=\"magenta\")\nv1, = ax.plot(x, val_results[0], c=\"blue\", ls=\"dashed\")\nv2, = ax.plot(x, val_results[1], c=\"brown\", ls=\"dashed\")\nv3, = ax.plot(x, val_results[2], c=\"green\", ls=\"dashed\")\nv4, = ax.plot(x, val_results[3], c=\"orange\", ls=\"dashed\")\nv5, = ax.plot(x, val_results[4], c=\"magenta\", ls=\"dashed\")\nax.legend((t1, t2, t3, t4, t5, v1, v2, v3, v4, v5), ('1st train fold', '2nd train fold', \"3rd train fold\", \"4th train fold\", \"5th train fold\", '1st val fold', '2nd val fold', \"3rd val fold\", \"4th val fold\", \"5th val fold\"), loc='upper right', shadow=True)\nax.set_xlabel('epochs')\nax.set_ylabel('loss')\nax.set_title('Train and validation results for 5 folds')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train and validation results\n\nimport matplotlib.pyplot as plt\nx = list(range(0, 100))\n\nfig, ax = plt.subplots()\nt1, = ax.plot(x, train_results[0], c=\"blue\")\nt2, = ax.plot(x, train_results[1], c=\"brown\")\nv1, = ax.plot(x, val_results[0], c=\"blue\", ls=\"dashed\")\nv2, = ax.plot(x, val_results[1], c=\"brown\", ls=\"dashed\")\nax.legend((t1, t2, v1, v2), ('1st train fold', '2nd train fold', '1st val fold', '2nd val fold'), loc='upper right', shadow=True)\nax.set_xlabel('epochs')\nax.set_ylabel('loss')\nax.set_title('Train and validation results for 5 folds')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inference for 15 sequences\ndata_loader = DataLoader(dataset, batch_size=15, collate_fn=collate, drop_last=True, shuffle=True)\ndata, target = next(iter(data_loader))\n\nmodel.eval()                                                   \nwith torch.no_grad():                                          \n    output, spikes = model(data)\n\n# Reshape targets and generated\ntargets = target.reshape(15, 28, 28, 1)\nimgs_gen = output.reshape(15, 28, 28, 1)\n\n# Join tensors for a singe image\ncombined = torch.cat((targets, imgs_gen), 0)\ncombined.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(15, 15))\ngrid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(2, 15),  # creates 2x2 grid of axes\n                 axes_pad=0.05,  # pad between axes in inch.\n                 )\n\nfor ax, im in zip(grid, combined):\n    # Iterating over the grid returns the Axes.\n    ax.imshow(im)\n    \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(15, 15))\ngrid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(2, 14),  # creates 2x2 grid of axes\n                 axes_pad=0.05,  # pad between axes in inch.\n                 )\n\nfor ax, im in zip(grid, spikes[14]):\n    # Iterating over the grid returns the Axes.\n    ax.imshow(im)\n    \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\n\nwith open(\"./\" + \"train_results.json\", 'w') as outfile:\n    json.dump(train_results, outfile)\nwith open(\"./\" + \"val_results.json\", 'w') as outfile:\n    json.dump(val_results, outfile)","metadata":{},"execution_count":null,"outputs":[]}]}
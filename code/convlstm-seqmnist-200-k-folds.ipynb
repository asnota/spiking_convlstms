{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch import optim\nfrom torch.utils.data import DataLoader, SubsetRandomSampler\nimport torchvision\nimport torchvision.transforms as T\nfrom sklearn.model_selection import KFold\nimport os\nimport copy\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python --version","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%pip install codecarbon comet_ml","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from comet_ml import Experiment\nfrom codecarbon import EmissionsTracker\nfrom datetime import datetime\n\n# Initialise and start CodeCarbon tracker\ntracker = EmissionsTracker()\ntracker.start()\n\nstart_time = datetime.now()\nprint(f'Start time is {start_time}')\n\n# Initialise the Comet experiment\nexperiment = Experiment(\n    api_key=\"XXXXXXXXXXXXXXXXXXXXXXXXX\",\n    project_name=\"\",\n    workspace=\"\",\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of numbers in a sequence\n\nsequences = [\n    [1, 2, 3, 6, 8],\n    [1, 4, 3, 6, 8],\n    [1, 5, 3, 6, 8],\n\n    [1, 2, 3, 6, 9],\n    [1, 4, 3, 6, 9],\n    [1, 5, 3, 6, 9],\n\n    [1, 2, 3, 7, 8],\n    [1, 4, 3, 7, 8],\n    [1, 5, 3, 7, 8],\n\n    [1, 2, 3, 7, 9],\n    [1, 4, 3, 7, 9],\n    [1, 5, 3, 7, 9],\n    #________________ 12\n\n    [1, 2, 6, 7, 8],\n    [1, 4, 6, 7, 8],\n    [1, 5, 6, 7, 8],\n\n    [1, 2, 6, 7, 9],\n    [1, 4, 6, 7, 9],\n    [1, 5, 6, 7, 9],\n\n    [1, 2, 6, 3, 8],\n    [1, 4, 6, 3, 8],\n    [1, 5, 6, 3, 8],\n\n    [1, 2, 6, 3, 9],\n    [1, 4, 6, 3, 9],\n    [1, 5, 6, 3, 9],\n    #________________ 24\n    [1, 2, 7, 3, 8],\n    [1, 4, 7, 3, 8],\n    [1, 5, 7, 3, 8],\n\n    [1, 2, 7, 3, 9],\n    [1, 4, 7, 3, 9],\n    [1, 5, 7, 3, 9],\n\n    [1, 2, 7, 9, 8],\n    [1, 4, 7, 9, 8],\n    [1, 5, 7, 9, 8],\n\n    [1, 2, 7, 8, 9],\n    [1, 4, 7, 8, 9],\n    [1, 5, 7, 8, 9],\n    #________________ 36\n    [2, 3, 4, 7, 8],\n    [2, 5, 4, 7, 8],\n    [2, 6, 4, 7, 8],\n\n    [2, 3, 4, 7, 9],\n    [2, 5, 4, 7, 9],\n    [2, 6, 4, 7, 9],\n\n    [2, 3, 4, 1, 8],\n    [2, 5, 4, 1, 8],\n    [2, 6, 4, 1, 8],\n\n    [2, 3, 4, 1, 9],\n    [2, 5, 4, 1, 9],\n    [2, 6, 4, 1, 9],\n    #________________ 48\n    [2, 3, 7, 8, 9],\n    [2, 5, 7, 8, 9],\n    [2, 6, 7, 8, 9],\n\n    [2, 3, 7, 9, 8],\n    [2, 5, 7, 9, 8],\n    [2, 6, 7, 9, 8],\n\n    [2, 3, 7, 8, 1],\n    [2, 5, 7, 8, 1],\n    [2, 6, 7, 8, 1],\n\n    [2, 3, 7, 9, 1],\n    [2, 5, 7, 9, 1],\n    [2, 6, 7, 9, 1],\n    #________________ 60\n    [2, 3, 8, 9, 1],\n    [2, 5, 8, 9, 1],\n    [2, 6, 8, 9, 1],\n\n    [2, 3, 8, 9, 7],\n    [2, 5, 8, 9, 7],\n    [2, 6, 8, 9, 7],\n\n    [2, 3, 8, 7, 1],\n    [2, 5, 8, 7, 1],\n    [2, 6, 8, 7, 1],\n\n    [2, 3, 8, 1, 7],\n    [2, 5, 8, 1, 7],\n    [2, 6, 8, 1, 7],\n    #________________ 72\n    [3, 4, 5, 8, 2],\n    [3, 6, 5, 8, 2],\n    [3, 7, 5, 8, 2],\n\n    [3, 4, 5, 2, 8],\n    [3, 6, 5, 2, 8],\n    [3, 7, 5, 2, 8],\n\n    [3, 4, 5, 8, 1],\n    [3, 6, 5, 8, 1],\n    [3, 7, 5, 8, 1],\n\n    [3, 4, 5, 1, 8],\n    [3, 6, 5, 1, 8],\n    [3, 7, 5, 1, 8],\n    #_______________ 84\n    [3, 4, 8, 9, 2],\n    [3, 6, 8, 9, 2],\n    [3, 7, 8, 9, 2],\n\n    [3, 4, 8, 2, 9],\n    [3, 6, 8, 2, 9],\n    [3, 7, 8, 2, 9],\n\n    [3, 4, 8, 9, 1],\n    [3, 6, 8, 9, 1],\n    [3, 7, 8, 9, 1],\n\n    [3, 4, 8, 1, 9],\n    [3, 6, 8, 1, 9],\n    [3, 7, 8, 1, 9],\n    #_______________ 96\n    [3, 4, 9, 8, 2],\n    [3, 6, 9, 8, 2],\n    [3, 7, 9, 8, 2],\n\n    [3, 4, 9, 2, 8],\n    [3, 6, 9, 2, 8],\n    [3, 7, 9, 2, 8],\n\n    [3, 4, 9, 8, 1],\n    [3, 6, 9, 8, 1],\n    [3, 7, 9, 8, 1],\n\n    [3, 4, 9, 1, 8],\n    [3, 6, 9, 1, 8],\n    [3, 7, 9, 1, 8],\n    #_______________ 108\n    [4, 5, 6, 9, 2],\n    [4, 7, 6, 9, 2],\n    [4, 8, 6, 9, 2],\n\n    [4, 5, 6, 2, 9],\n    [4, 7, 6, 2, 9],\n    [4, 8, 6, 2, 9],\n\n    [4, 5, 6, 9, 3],\n    [4, 7, 6, 9, 3],\n    [4, 8, 6, 9, 3],\n\n    [4, 5, 6, 3, 9],\n    [4, 7, 6, 3, 9],\n    [4, 8, 6, 3, 9],\n    #_______________ 120\n    [4, 5, 9, 3, 2],\n    [4, 7, 9, 3, 2],\n    [4, 8, 9, 3, 2],\n\n    [4, 5, 9, 2, 3],\n    [4, 7, 9, 2, 3],\n    [4, 8, 9, 2, 3],\n\n    [4, 5, 9, 1, 3],\n    [4, 7, 9, 1, 3],\n    [4, 8, 9, 1, 3],\n\n    [4, 5, 9, 3, 1],\n    [4, 7, 9, 3, 1],\n    [4, 8, 9, 3, 1],\n    #_______________ 132\n    [4, 5, 1, 3, 2],\n    [4, 7, 1, 3, 2],\n    [4, 8, 1, 3, 2],\n\n    [4, 5, 1, 2, 3],\n    [4, 7, 1, 2, 3],\n    [4, 8, 1, 2, 3],\n\n    [4, 5, 1, 9, 3],\n    [4, 7, 1, 9, 3],\n    [4, 8, 1, 9, 3],\n\n    [4, 5, 1, 3, 9],\n    [4, 7, 1, 3, 9],\n    [4, 8, 1, 3, 9],\n    #_______________ 144\n    [5, 6, 7, 1, 2],\n    [5, 8, 7, 1, 2],\n    [5, 9, 7, 1, 2],\n\n    [5, 6, 7, 2, 1],\n    [5, 8, 7, 2, 1],\n    [5, 9, 7, 2, 1],\n\n    [5, 6, 7, 3, 2],\n    [5, 8, 7, 3, 2],\n    [5, 9, 7, 3, 2],\n\n    [5, 6, 7, 2, 3],\n    [5, 8, 7, 2, 3],\n    [5, 9, 7, 2, 3],\n    #_______________ 156\n    [5, 6, 1, 2, 3],\n    [5, 8, 1, 2, 3],\n    [5, 9, 1, 2, 3],\n\n    [5, 6, 1, 3, 2],\n    [5, 8, 1, 3, 2],\n    [5, 9, 1, 3, 2],\n\n    [5, 6, 1, 3, 4],\n    [5, 8, 1, 3, 4],\n    [5, 9, 1, 3, 4],\n\n    [5, 6, 1, 4, 3],\n    [5, 8, 1, 4, 3],\n    [5, 9, 1, 4, 3],\n    #_______________ 168\n    [5, 6, 3, 4, 1],\n    [5, 8, 3, 4, 1],\n    [5, 9, 3, 4, 1],\n\n    [5, 6, 3, 1, 4],\n    [5, 8, 3, 1, 4],\n    [5, 9, 3, 1, 4],\n\n    [5, 6, 3, 4, 2],\n    [5, 8, 3, 4, 2],\n    [5, 9, 3, 4, 2],\n\n    [5, 6, 3, 2, 4],\n    [5, 8, 3, 2, 4],\n    [5, 9, 3, 2, 4],\n    #_______________ 180\n    [6, 7, 8, 2, 3],\n    [6, 9, 8, 2, 3],\n    [6, 1, 8, 2, 3],\n\n    [6, 7, 8, 3, 2],\n    [6, 9, 8, 3, 2],\n    [6, 1, 8, 3, 2],\n\n    [6, 7, 8, 2, 5],\n    [6, 9, 8, 2, 5],\n    [6, 1, 8, 2, 5],\n\n    [6, 7, 8, 5, 2],\n    [6, 9, 8, 5, 2],\n    [6, 1, 8, 5, 2],\n    #_______________ 192\n    [6, 7, 2, 3, 4],\n    [6, 9, 2, 3, 4],\n    [6, 1, 2, 3, 4],\n\n    [6, 7, 2, 4, 3],\n    [6, 9, 2, 4, 3],\n    [6, 1, 2, 4, 3],\n\n    [6, 7, 2, 4, 5],\n    [6, 9, 2, 4, 5],\n    [6, 1, 2, 4, 5],\n\n    [6, 7, 2, 5, 4],\n    [6, 9, 2, 5, 4],\n    [6, 1, 2, 5, 4],\n    #_______________ 204\n    [6, 7, 3, 4, 5],\n    [6, 9, 3, 4, 5],\n    [6, 1, 3, 4, 5],\n\n    [6, 7, 3, 5, 4],\n    [6, 9, 3, 5, 4],\n    [6, 1, 3, 5, 4],\n\n    [6, 7, 3, 2, 5],\n    [6, 9, 3, 2, 5],\n    [6, 1, 3, 2, 5],\n\n    [6, 7, 3, 5, 2],\n    [6, 9, 3, 5, 2],\n    [6, 1, 3, 5, 2],\n    #_______________ 216\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = torchvision.datasets.MNIST(\"./\", train = False, download = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Patch images with labels\ndef find_match(number):\n    for entry in dataset:\n        if entry[1] == number:\n            match = entry\n            break\n    return match\n\nimage_sequences = []\nimage_label_sequences = []\nfor sequence in sequences:\n    image_sequence = []\n    image_label_sequence = []\n    for num in sequence:\n        entry = find_match(num)\n        image_sequence.append(entry[0])\n        image_label_sequence.append(entry)\n    image_sequences.append(image_sequence)\n    image_label_sequences.append(image_label_sequence)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert to matrices and resize\n\ntf = T.Compose([\n     T.Resize((28)),\n     T.ToTensor() # Returns a tensor with normalized values between 0 and 1\n])\nseqs = []\n\nfor seq in image_sequences:\n    img_tensors = []\n    for img in seq:\n        img_tensor = tf(img)\n        img_tensors.append(img_tensor)\n    img_tensors_stack = torch.stack(img_tensors)\n    seqs.append(img_tensors_stack)\n\nseqs_stack = torch.stack(seqs)\nseqs_reshaped = seqs_stack.reshape(216, 1, 5, 28, 28)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Utils\ndef collate(batch):\n    batch = torch.stack(batch)    \n    #batch = batch / 255.0\n    batch = batch.to(device)    \n    return batch[:,:,0:4], batch[:,:,4]\n\ndef reset_weights(m):\n  '''\n    Try resetting model weights to avoid\n    weight leakage.\n  '''\n  for layer in m.children():\n        if hasattr(layer, 'reset_parameters'):\n            print(f'Reset trainable parameters of layer = {layer}')\n            layer.reset_parameters()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(seqs_reshaped, batch_size=1, collate_fn=collate, drop_last=True)\ndata, target = next(iter(train_loader))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### ConvLSTM cell and layer\n### ConvLSTM cell\nclass ConvLSTMCell(nn.Module):\n    def __init__(self, in_channels, out_channels, \n    kernel_size, padding, activation, frame_size):\n        super(ConvLSTMCell, self).__init__()\n        if activation == \"tanh\":\n            self.activation = torch.tanh # activation=\"tanh\"\n        elif activation == \"relu\":\n            self.activation = torch.relu\n        \n        # Idea adapted from https://github.com/ndrplz/ConvLSTM_pytorch\n        self.conv = nn.Conv2d(\n            in_channels=in_channels + out_channels, # num_channels=1 num_kernels=28 = 29\n            out_channels=4 * out_channels, # 28 x 4 = 112\n            kernel_size=kernel_size,  # kernel_size=(3, 3)\n            padding=padding)  # padding=(1, 1)         \n\n        # Initialize weights for Hadamard Products - with torch.rand the values are between 0 and 1\n        self.W_ci = nn.Parameter(torch.rand(out_channels, *frame_size)) # out-channels=28\n        self.W_co = nn.Parameter(torch.rand(out_channels, *frame_size)) # frame_size=(28, 28)\n        self.W_cf = nn.Parameter(torch.rand(out_channels, *frame_size))\n\n    def forward(self, X, H_prev, C_prev):\n        # X is a frame\n        \n        conv_output = self.conv(torch.cat([X, H_prev], dim=1)) # concatenate x and hidden state\n        #print(conv_output.shape) # 8 matrices of size torch.Size([15, 112, 28, 28])\n   \n        i_conv, f_conv, C_conv, o_conv = torch.chunk(conv_output, chunks=4, dim=1)\n\n        input_gate = torch.sigmoid(i_conv + self.W_ci * C_prev)\n        forget_gate = torch.sigmoid(f_conv + self.W_cf * C_prev)\n        \n        # Prevent NaNs - convert it to numbers\n        input_gate_without_nan = torch.nan_to_num(input_gate)\n        forget_gate_without_nan = torch.nan_to_num(forget_gate)\n\n        # Current Cell output\n        current_cell_state = forget_gate_without_nan*C_prev + input_gate_without_nan * self.activation(C_conv)\n        \n        output_gate = torch.sigmoid(o_conv + self.W_co * current_cell_state)\n        output_gate_without_nan = torch.nan_to_num(output_gate)\n\n        # Current Hidden State\n        current_hidden_state = output_gate_without_nan * self.activation(current_cell_state)\n        \n        return current_hidden_state, current_cell_state\n\n### ConvLSTM layer\nclass ConvLSTM(nn.Module):\n    def __init__(self, in_channels, out_channels, \n    kernel_size, padding, activation, frame_size):\n\n        super(ConvLSTM, self).__init__()\n        self.out_channels = out_channels\n\n        # We will unroll this over time steps\n        self.convLSTMcell = ConvLSTMCell(in_channels, out_channels, \n        kernel_size, padding, activation, frame_size)\n\n    def forward(self, X):\n        # X is a frame sequence (batch_size, num_channels, seq_len, height, width)\n        # Get the dimensions\n        batch_size, _, seq_len, height, width = X.size()\n\n        # Initialize output\n        output = torch.zeros(batch_size, self.out_channels, seq_len, \n        height, width, device=device)\n        \n        # Initialize Hidden State\n        H = torch.zeros(batch_size, self.out_channels, \n        height, width, device=device)\n\n        # Initialize Cell Input\n        C = torch.zeros(batch_size,self.out_channels, \n        height, width, device=device)\n\n        # Unroll over time steps\n        for time_step in range(seq_len):\n            H, C = self.convLSTMcell(X[:,:,time_step], H, C)\n            output[:,:,time_step] = H\n        return output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Try convLSTM cell initialisation\n# Initialize output\nbatch_size=1\nin_channels=1\nout_channels=28\nkernel_size=(3, 3)\npadding=(1, 1)\nactivation=\"tanh\"\nframe_size=(28, 28)\noutput = torch.zeros(batch_size, out_channels, seq_len, height, width, device=device)\nprint(output.shape)\n        \n# Initialize Hidden State\nH = torch.zeros(batch_size, out_channels, height, width, device=device)\nprint(H.shape)\n\n# Initialize Cell Input\nC = torch.zeros(batch_size, out_channels, height, width, device=device)\nprint(C.shape)\n\nconvLSTMcell = ConvLSTMCell(in_channels, out_channels, \n        kernel_size, padding, activation, frame_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### ConvLSTM model 1 layer\n\nclass Seq2Seq(nn.Module):\n    def __init__(self, num_channels, num_kernels, kernel_size, padding, \n    activation, frame_size):\n        super(Seq2Seq, self).__init__()\n        self.sequential = nn.Sequential()\n\n        # Add First layer (Different in_channels than the rest)\n        self.sequential.add_module(\n            \"convlstm1\", ConvLSTM(\n                in_channels=num_channels, out_channels=num_kernels,\n                kernel_size=kernel_size, padding=padding, \n                activation=activation, frame_size=frame_size)\n        )\n\n        self.sequential.add_module(\n            \"batchnorm1\", nn.BatchNorm3d(num_features=num_kernels)\n        ) \n\n        # Add Convolutional Layer to predict output frame\n        self.conv = nn.Conv2d(\n            in_channels=num_kernels, out_channels=num_channels,\n            kernel_size=kernel_size, padding=padding)\n\n    def forward(self, X):\n        # Forward propagation through all the layers\n        output = self.sequential(X)\n\n        # Return only the last output frame\n        output = self.conv(output[:,:,-1])        \n        return nn.Sigmoid()(output)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### K-fold Cross Validator\n# Params\ntorch.manual_seed(42)\nnum_epochs = 100\ncriterion = nn.BCELoss(reduction='sum')\n\n# Fold results storage objects\ntrain_start_results = {}\nval_start_results = {}\n\ntrain_end_results = {}\nval_end_results = {}\n\n# Per fold epoch results storage objects\ntrain_results_per_epoch = []\nval_results_per_epoch = []\n\ntrain_results = []\nval_results = []\n\n# Define the K-fold Cross Validator\nk_folds = 5\nkfold = KFold(n_splits=k_folds, shuffle=True)\n\n# Whole dataset\ndataset = seqs_reshaped\n\n# K-fold Cross Validation model evaluation\nfor fold, (train_ids, val_ids) in enumerate(kfold.split(dataset)):\n    print(f'FOLD {fold}')\n    \n    # Sample elements randomly from a given list of ids, no replacement.\n    train_subsampler = SubsetRandomSampler(train_ids)\n    val_subsampler = SubsetRandomSampler(val_ids)\n    \n    # Define data loaders for training and testing data in this fold\n    train_loader = DataLoader(dataset, batch_size=15, collate_fn=collate, sampler=train_subsampler)\n    val_loader = DataLoader(dataset, batch_size=15, collate_fn=collate, sampler=val_subsampler)\n    \n    # Initialization\n    model = Seq2Seq(num_channels=1, num_kernels=28, kernel_size=(3, 3), padding=(1, 1), activation=\"tanh\", frame_size=(28, 28)).to(device)\n    model.apply(reset_weights)  \n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n    \n    train_results_per_epoch = []\n    val_results_per_epoch = []\n    for epoch in range(1, num_epochs+1):\n        train_loss = 0                                                 \n        model.train()        \n        for batch, (x, y) in enumerate(train_loader, 1):\n            output = model(x)\n            \n            optimizer.zero_grad()\n            \n            loss_train = criterion(output.flatten(), y.flatten())       \n            loss_train.backward()\n            \n            optimizer.step()\n                                      \n            train_loss += loss_train.item()                                 \n        total_train_loss = train_loss / len(train_loader.dataset)\n        train_results_per_epoch.append(total_train_loss)\n        \n        val_loss = 0                                                 \n        model.eval()                                                   \n        with torch.no_grad():                                          \n            for x, y in val_loader:                          \n                output = model(x)                                   \n                loss_val = criterion(output.flatten(), y.flatten())                \n                val_loss += loss_val.item()                                \n        total_val_loss = val_loss / len(val_loader.dataset)\n        val_results_per_epoch.append(total_val_loss)\n        \n        # Store scores        \n        if epoch == 1:\n            val_start_results[fold] = total_val_loss\n            train_start_results[fold] = total_train_loss\n        else:\n            val_end_results[fold] = total_val_loss\n            train_end_results[fold] = total_train_loss\n            \n        print(\"Epoch:{} Training Loss:{:.2f} Validation Loss:{:.2f}\\n\".format(\n            epoch, total_train_loss, total_val_loss))\n    train_results.append(train_results_per_epoch)\n    val_results.append(val_results_per_epoch)\n    \n    # Saving the model\n    save_path = f'./convlstm-seqgmnist200-model-fold-{fold}.pth'\n    torch.save(model.state_dict(), save_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Stop CO2 tracker and print emissions\n\nemissions: float = tracker.stop()\nprint(f\"Emissions: {emissions} kg\")\n\n# Calculate the time spent\nstop_time = datetime.now() - start_time\ntime_spend = start_time - stop_time\n\n# Time logs\nexperiment.log_metric(\"start_time\", start_time) \nexperiment.log_metric(\"stop_time\", stop_time)\nexperiment.log_metric(\"time_spend\", time_spend)\n\n# Turn off Comet\nexperiment.end()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print start fold results\nprint(f'Start K-FOLD RESULTS FOR {k_folds} FOLDS')\nsum = 0.0\nfor key, value in train_start_results.items():\n    print(f'Fold {key}: {value}')\n    sum += value\nprint(f'Average train: {sum/len(train_start_results.items())}')\n\nsum = 0.0\nfor key, value in val_start_results.items():\n    print(f'Fold {key}: {value}')\n    sum += value\nprint(f'Average val: {sum/len(val_start_results.items())}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print final fold results\nprint(f'End K-FOLD RESULTS FOR {k_folds} FOLDS')\nsum = 0.0\nfor key, value in train_end_results.items():\n    print(f'Fold {key}: {value}')\n    sum += value\nprint(f'Average train: {sum/len(train_end_results.items())}')\n\nsum = 0.0\nfor key, value in val_end_results.items():\n    print(f'Fold {key}: {value}')\n    sum += value\nprint(f'Average val: {sum/len(val_end_results.items())}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train and validation results\n\nimport matplotlib.pyplot as plt\nx = list(range(0, 100))\n\nfig, ax = plt.subplots()\nt1, = ax.plot(x, train_results[0], c=\"blue\")\nt2, = ax.plot(x, train_results[1], c=\"brown\")\nt3, = ax.plot(x, train_results[2], c=\"green\")\nt4, = ax.plot(x, train_results[3], c=\"orange\")\nt5, = ax.plot(x, train_results[4], c=\"magenta\")\nv1, = ax.plot(x, val_results[0], c=\"blue\", ls=\"dashed\")\nv2, = ax.plot(x, val_results[1], c=\"brown\", ls=\"dashed\")\nv3, = ax.plot(x, val_results[2], c=\"green\", ls=\"dashed\")\nv4, = ax.plot(x, val_results[3], c=\"orange\", ls=\"dashed\")\nv5, = ax.plot(x, val_results[4], c=\"magenta\", ls=\"dashed\")\nax.legend((t1, t2, t3, t4, t5, v1, v2, v3, v4, v5), ('1st train fold', '2nd train fold', \"3rd train fold\", \"4th train fold\", \"5th train fold\", '1st val fold', '2nd val fold', \"3rd val fold\", \"4th val fold\", \"5th val fold\"), loc='upper right', shadow=True)\nax.set_xlabel('epochs')\nax.set_ylabel('loss')\nax.set_title('Train and validation results for 5 folds')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train and validation results\n\nimport matplotlib.pyplot as plt\nx = list(range(0, 100))\n\nfig, ax = plt.subplots()\nt1, = ax.plot(x, train_results[0], c=\"blue\")\nt2, = ax.plot(x, train_results[1], c=\"brown\")\nv1, = ax.plot(x, val_results[0], c=\"blue\", ls=\"dashed\")\nv2, = ax.plot(x, val_results[1], c=\"brown\", ls=\"dashed\")\nax.legend((t1, t2, v1, v2), ('1st train fold', '2nd train fold', '1st val fold', '2nd val fold'), loc='upper right', shadow=True)\nax.set_xlabel('epochs')\nax.set_ylabel('loss')\nax.set_title('Train and validation results for 5 folds')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inference for 15 sequences\ndata_loader = DataLoader(dataset, batch_size=15, collate_fn=collate, drop_last=True, shuffle=True)\ndata, target = next(iter(data_loader))\n\nmodel.eval()                                                   \nwith torch.no_grad():                                          \n    output = model(data)\n\n# Reshape targets and generated\ntargets = target.reshape(15, 28, 28, 1)\nimgs_gen = output.reshape(15, 28, 28, 1)\n\n# Join tensors for a singe image\ncombined = torch.cat((targets, imgs_gen), 0)\ncombined.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(15, 15))\ngrid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(2, 15),  # creates 2x2 grid of axes\n                 axes_pad=0.05,  # pad between axes in inch.\n                 )\n\nfor ax, im in zip(grid, combined):\n    # Iterating over the grid returns the Axes.\n    ax.imshow(im)\n    \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\n\nwith open(\"./\" + \"train_results.json\", 'w') as outfile:\n    json.dump(train_results, outfile)\nwith open(\"./\" + \"val_results.json\", 'w') as outfile:\n    json.dump(val_results, outfile)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}
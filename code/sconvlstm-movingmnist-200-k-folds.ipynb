{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# Install SNN dependency\n!pip install snntorch\n\nimport snntorch as snn\nfrom snntorch import surrogate\n\nimport numpy as np\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader, SubsetRandomSampler\nfrom sklearn.model_selection import KFold\nimport os\nimport copy\n\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%pip install codecarbon comet_ml","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from comet_ml import Experiment\nfrom codecarbon import EmissionsTracker\nfrom datetime import datetime\n\n# Initialise and start CodeCarbon tracker\ntracker = EmissionsTracker()\ntracker.start()\n\nstart_time = datetime.now()\nprint(f'Start time is {start_time}')\n\n# Initialise the Comet experiment\nexperiment = Experiment(\n    api_key=\"XXXXXXXXXXXXXXXXXXXXXXXXX\",\n    project_name=\"\",\n    workspace=\"\",\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Data\n! wget -q https://www.cs.toronto.edu/~nitish/unsupervised_video/mnist_test_seq.npy\n\nimport numpy as np\nMovingMNIST = np.load('mnist_test_seq.npy').transpose(1, 0, 2, 3)\nMovingMNIST.shape # Custom dataset: (216, 5, 28, 28)\n\n# Shuffle Data\nnp.random.shuffle(MovingMNIST)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MovingMNIST_reduced = MovingMNIST[:216]\nMovingMNIST_reduced.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Resize 64x64 images to 28x28\nimport torchvision.transforms as T\nimport torch\n\ntf = T.Compose([\n     T.ToPILImage(),\n     T.Resize((28)),\n     T.ToTensor()\n])\n\nresized_seqs = []\nfor seq in MovingMNIST_reduced:\n    resized_imgs = []\n    for img in seq[:5]:\n        resized_img = tf(img)\n        resized_imgs.append(resized_img)\n    resized_imgs_stack = torch.stack(resized_imgs)\n    resized_seqs.append(resized_imgs_stack)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resized_seqs_stack = torch.stack(resized_seqs)\nresized_seqs_stack.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resized_seqs_reshaped = resized_seqs_stack.reshape(216, 1, 5, 28, 28)\nresized_seqs_reshaped.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Utils\ndef collate(batch):\n    batch = torch.stack(batch)\n    batch = batch.to(device)    \n    return batch[:,:,0:4], batch[:,:,4]\n\ndef reset_weights(m):\n  '''\n    Try resetting model weights to avoid\n    weight leakage.\n  '''\n  for layer in m.children():\n        if hasattr(layer, 'reset_parameters'):\n            print(f'Reset trainable parameters of layer = {layer}')\n            layer.reset_parameters()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(resized_seqs_reshaped, batch_size=15, collate_fn=collate, drop_last=True)\ndata, target = next(iter(train_loader))\nprint(data.size())\nprint(target.size())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### SConvLSTM layer\nclass SConvLSTMLayer(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size):\n\n        super(SConvLSTMLayer, self).__init__()\n        self.out_channels = out_channels\n\n        # We will unroll this over time steps        \n        # Params\n        spike_grad_lstm = surrogate.straight_through_estimator()\n\n        # SConvLSTM cell\n        self.sclstm = snn.SConv2dLSTM(in_channels=in_channels, out_channels=out_channels, \n                        kernel_size=kernel_size, max_pool=2, spike_grad=spike_grad_lstm)\n\n    def forward(self, X):\n        # X is a frame sequence (batch_size, num_channels, seq_len, height, width)\n        # Get the dimensions\n        batch_size, _, seq_len, height, width = X.size()\n        \n        # Initialize hidden states and outputs at t=0\n        syn1, mem1 = self.sclstm.init_sconv2dlstm()\n\n        # Initialize output\n        output = torch.zeros(batch_size, self.out_channels, seq_len, \n        height, width, device=device)\n        \n        spk_output = torch.zeros(batch_size, self.out_channels, seq_len, \n        14, 14, device=device)\n        \n        # Initialize Hidden State\n        H = torch.zeros(batch_size, self.out_channels, \n        height, width, device=device)\n\n        # Initialize Cell Input\n        C = torch.zeros(batch_size,self.out_channels, \n        height, width, device=device)\n\n        # Unroll over time steps\n        for time_step in range(seq_len):\n            spk, H, C = self.sclstm(X[:,:,time_step], H, C)\n            output[:,:,time_step] = H\n            spk_output[:,:,time_step] = spk\n        return output, spk_output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### SConvLSTM model 1 layer\n\nclass SConvLSTMModel(nn.Module):\n    def __init__(self, num_channels, num_kernels, kernel_size, padding):\n        super(SConvLSTMModel, self).__init__()\n        \n        # First csconvlstm layer\n        self.sconvlstm_layer = SConvLSTMLayer(in_channels=num_channels, out_channels=num_kernels,\n                                        kernel_size=kernel_size)\n        # Batchnorm layer\n        self.batchnorm3d = nn.BatchNorm3d(num_features=num_kernels)\n\n        # Convolutional Layer to predict output frame\n        self.conv = nn.Conv2d(\n            in_channels=num_kernels, out_channels=num_channels,\n            kernel_size=kernel_size, padding=padding)\n\n    def forward(self, X):\n        \n        # Forward propagation through all the layers\n        sconvlstm_layer_membrane, sconvlstm_layer_spikes = self.sconvlstm_layer(X)\n        sconvlstm_batchnorm = self.batchnorm3d(sconvlstm_layer_membrane)\n        \n        # Return only the last output frame\n        output = self.conv(sconvlstm_batchnorm[:,:,-1])\n        spikes_output = sconvlstm_layer_spikes[:,:,-1]\n        \n        return nn.Sigmoid()(output), spikes_output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### K-fold Cross Validator\n# Params\ntorch.manual_seed(42)\nnum_epochs = 100\ncriterion = nn.BCELoss(reduction='sum')\n\n# Fold results storage objects\ntrain_start_results = {}\nval_start_results = {}\n\ntrain_end_results = {}\nval_end_results = {}\n\n# Per fold epoch results storage objects\ntrain_results_per_epoch = []\nval_results_per_epoch = []\n\ntrain_results = []\nval_results = []\n\nspiked_targets_train = []\nspiked_targets_val = []\n\n# Define the K-fold Cross Validator\nk_folds = 5\nkfold = KFold(n_splits=k_folds, shuffle=True)\n\n# Whole dataset\ndataset = resized_seqs_reshaped\n\n# K-fold Cross Validation model evaluation\nfor fold, (train_ids, val_ids) in enumerate(kfold.split(dataset)):\n    print(f'FOLD {fold}')\n    \n    # Sample elements randomly from a given list of ids, no replacement.\n    train_subsampler = SubsetRandomSampler(train_ids)\n    val_subsampler = SubsetRandomSampler(val_ids)\n    \n    # Define data loaders for training and testing data in this fold\n    train_loader = DataLoader(dataset, batch_size=15, collate_fn=collate, sampler=train_subsampler)\n    val_loader = DataLoader(dataset, batch_size=15, collate_fn=collate, sampler=val_subsampler)\n    \n    # Initialization\n    model = SConvLSTMModel(num_channels=1, num_kernels=28, kernel_size=(3, 3), padding=(1, 1)).to(device)\n    model.apply(reset_weights)  \n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n    \n    train_results_per_epoch = []\n    val_results_per_epoch = []\n    for epoch in range(1, num_epochs+1):\n        train_loss = 0                                                 \n        model.train()        \n        for batch, (x, y) in enumerate(train_loader, 1):\n            output, spikes = model(x)\n            \n            optimizer.zero_grad()\n            \n            loss_train = criterion(output.flatten(), y.flatten())       \n            loss_train.backward()\n            \n            optimizer.step()\n                                      \n            train_loss += loss_train.item()\n            #spiked_targets_train.append(spikes)\n        total_train_loss = train_loss / len(train_loader.dataset)\n        train_results_per_epoch.append(total_train_loss)\n        \n        val_loss = 0                                                 \n        model.eval()                                                   \n        with torch.no_grad():                                          \n            for x, y in val_loader:                          \n                output, spikes = model(x)                                   \n                loss_val = criterion(output.flatten(), y.flatten())                \n                val_loss += loss_val.item()\n                #spiked_targets_val.append(spikes)\n        total_val_loss = val_loss / len(val_loader.dataset)\n        val_results_per_epoch.append(total_val_loss)\n        \n        # Store scores        \n        if epoch == 1:\n            val_start_results[fold] = total_val_loss\n            train_start_results[fold] = total_train_loss\n        else:\n            val_end_results[fold] = total_val_loss\n            train_end_results[fold] = total_train_loss\n            \n        print(\"Epoch:{} Training Loss:{:.2f} Validation Loss:{:.2f}\\n\".format(\n            epoch, total_train_loss, total_val_loss))\n    train_results.append(train_results_per_epoch)\n    val_results.append(val_results_per_epoch)\n    \n    # Saving the model\n    save_path = f'./convlstm-seqgmnist200-model-fold-{fold}.pth'\n    torch.save(model.state_dict(), save_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Stop CO2 tracker and print emissions\n\nemissions: float = tracker.stop()\nprint(f\"Emissions: {emissions} kg\")\n\n# Calculate the time spent\nstop_time = datetime.now() - start_time\ntime_spend = start_time - stop_time\n\n# Time logs\nexperiment.log_metric(\"start_time\", start_time) \nexperiment.log_metric(\"stop_time\", stop_time)\nexperiment.log_metric(\"time_spend\", time_spend)\n\n# Turn off Comet\nexperiment.end()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print start fold results\nprint(f'Start K-FOLD RESULTS FOR {k_folds} FOLDS')\nsum = 0.0\nfor key, value in train_start_results.items():\n    print(f'Fold {key}: {value}')\n    sum += value\nprint(f'Average train: {sum/len(train_start_results.items())}')\n\nsum = 0.0\nfor key, value in val_start_results.items():\n    print(f'Fold {key}: {value}')\n    sum += value\nprint(f'Average val: {sum/len(val_start_results.items())}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print final fold results\nprint(f'End K-FOLD RESULTS FOR {k_folds} FOLDS')\nsum = 0.0\nfor key, value in train_end_results.items():\n    print(f'Fold {key}: {value}')\n    sum += value\nprint(f'Average train: {sum/len(train_end_results.items())}')\n\nsum = 0.0\nfor key, value in val_end_results.items():\n    print(f'Fold {key}: {value}')\n    sum += value\nprint(f'Average val: {sum/len(val_end_results.items())}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inference for 15 sequences\ndata_loader = DataLoader(dataset, batch_size=15, collate_fn=collate, drop_last=True, shuffle=True)\ndata, target = next(iter(data_loader))\n\nmodel.eval()                                                   \nwith torch.no_grad():                                          \n    output, spikes = model(data)\n\n# Reshape targets and generated\ntargets = target.reshape(15, 28, 28, 1)\nimgs_gen = output.reshape(15, 28, 28, 1)\n\n# Join tensors for a singe image\ncombined = torch.cat((targets, imgs_gen), 0)\ncombined.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(15, 15))\ngrid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(2, 15),  # creates 2x2 grid of axes\n                 axes_pad=0.05,  # pad between axes in inch.\n                 )\n\nfor ax, im in zip(grid, combined):\n    # Iterating over the grid returns the Axes.\n    ax.imshow(im)\n    \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train and validation results\n\nimport matplotlib.pyplot as plt\nx = list(range(0, 100))\n\nfig, ax = plt.subplots()\nt1, = ax.plot(x, train_results[0], c=\"blue\")\nt2, = ax.plot(x, train_results[1], c=\"brown\")\nt3, = ax.plot(x, train_results[2], c=\"green\")\nt4, = ax.plot(x, train_results[3], c=\"orange\")\nt5, = ax.plot(x, train_results[4], c=\"magenta\")\nv1, = ax.plot(x, val_results[0], c=\"blue\", ls=\"dashed\")\nv2, = ax.plot(x, val_results[1], c=\"brown\", ls=\"dashed\")\nv3, = ax.plot(x, val_results[2], c=\"green\", ls=\"dashed\")\nv4, = ax.plot(x, val_results[3], c=\"orange\", ls=\"dashed\")\nv5, = ax.plot(x, val_results[4], c=\"magenta\", ls=\"dashed\")\nax.legend((t1, t2, t3, t4, t5, v1, v2, v3, v4, v5), ('1st train fold', '2nd train fold', \"3rd train fold\", \"4th train fold\", \"5th train fold\", '1st val fold', '2nd val fold', \"3rd val fold\", \"4th val fold\", \"5th val fold\"), loc='upper right', shadow=True)\nax.set_xlabel('epochs')\nax.set_ylabel('loss')\nax.set_title('Train and validation results for 5 folds')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train\nfig, ax = plt.subplots()\nt1, = ax.plot(x, train_results[0], c=\"blue\")\nt2, = ax.plot(x, train_results[1], c=\"brown\")\nt3, = ax.plot(x, train_results[2], c=\"green\")\nt4, = ax.plot(x, train_results[3], c=\"orange\")\nt5, = ax.plot(x, train_results[4], c=\"magenta\")\nax.legend((t1, t2, t3, t4, t5), ('1st train fold', '2nd train fold', \"3rd train fold\", \"4th train fold\", \"5th train fold\"), loc='upper right', shadow=True)\nax.set_xlabel('epochs')\nax.set_ylabel('loss')\nax.set_title('Train results for 5 folds')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Validation\nfig, ax = plt.subplots()\nv1, = ax.plot(x, val_results[0], c=\"blue\", ls=\"dashed\")\nv2, = ax.plot(x, val_results[1], c=\"brown\", ls=\"dashed\")\nv3, = ax.plot(x, val_results[2], c=\"green\", ls=\"dashed\")\nv4, = ax.plot(x, val_results[3], c=\"orange\", ls=\"dashed\")\nv5, = ax.plot(x, val_results[4], c=\"magenta\", ls=\"dashed\")\nax.legend((v1, v2, v3, v4, v5), (\"1st val fold\", \"2nd val fold\", \"3rd val fold\", \"4th val fold\", \"5th val fold\"), loc='upper right', shadow=True)\nax.set_xlabel('epochs')\nax.set_ylabel('loss')\nax.set_title('Validation results for 5 folds')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\n\nwith open(\"./\" + \"train_results.json\", 'w') as outfile:\n    json.dump(train_results, outfile)\nwith open(\"./\" + \"val_results.json\", 'w') as outfile:\n    json.dump(val_results, outfile)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}